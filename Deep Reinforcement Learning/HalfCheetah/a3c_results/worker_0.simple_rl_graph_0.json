last_checkpoint_saving_time: 
1547717376.891836
improve_steps: 
<rl_coach.core_types.TrainingSteps object at 0x7fb68af4abe0>
preset_validation_params: 
"PresetValidationParameters" {
    "max_episodes_to_achieve_reward": 1000,
    "min_reward_threshold": 400,
    "num_workers": 8,
    "reward_test_level": "inverted_pendulum",
    "test": true,
    "test_using_a_trace_test": true,
    "trace_max_env_steps": 5000,
    "trace_test_levels": {
        "0": "inverted_pendulum",
        "1": "hopper"
    }
}

steps_between_evaluation_periods: 
<rl_coach.core_types.EnvironmentEpisodes object at 0x7fb68af4a588>
_phase: 
RunPhase.UNDEFINED
checkpoint_id: 
0
visualization_parameters: 
"VisualizationParameters" {
    "add_rendered_image_to_env_response": false,
    "dump_csv": true,
    "dump_gifs": false,
    "dump_in_episode_signals": false,
    "dump_mp4": false,
    "dump_parameters_documentation": true,
    "dump_signals_to_csv_every_x_episodes": 5,
    "max_fps_for_human_control": 10,
    "native_rendering": false,
    "print_networks_summary": false,
    "render": true,
    "tensorboard": false,
    "video_dump_filters": {
        "0": {
            "run_phases": {
                "0": {
                    "_name_": "TEST",
                    "_value_": "Testing",
                    "__objclass__": "<enum 'RunPhase'>"
                }
            },
            "__class__": "SelectedPhaseOnlyDumpFilter"
        },
        "1": {
            "max_reward_achieved": -Infinity,
            "__class__": "MaxDumpFilter"
        }
    }
}

sess: 
<tensorflow.python.client.session.Session object at 0x7fb670b2da90>
evaluation_steps: 
<rl_coach.core_types.EnvironmentEpisodes object at 0x7fb68af4a630>
task_parameters: 
"TaskParameters" {
    "apply_stop_condition": false,
    "checkpoint_restore_dir": null,
    "checkpoint_save_dir": null,
    "checkpoint_save_secs": null,
    "evaluate_only": false,
    "experiment_path": "./experiments/hc_mujoco/17_01_2019-10_29",
    "export_onnx_graph": false,
    "framework_type": {
        "_name_": "tensorflow",
        "_value_": "TensorFlow",
        "__objclass__": "<enum 'Frameworks'>"
    },
    "num_gpu": 1,
    "seed": null,
    "task_index": 0,
    "use_cpu": false
}

heatup_steps: 
<rl_coach.core_types.EnvironmentSteps object at 0x7fb68af4a470>
checkpoint_saver: 
<rl_coach.saver.SaverCollection object at 0x7fb670460f28>
total_steps_counters: 
RunPhase.TRAIN: <rl_coach.core_types.TotalStepsCounter object at 0x7fb68aa8a4e0>
RunPhase.HEATUP: <rl_coach.core_types.TotalStepsCounter object at 0x7fb68aa8a470>
RunPhase.TEST: <rl_coach.core_types.TotalStepsCounter object at 0x7fb68aa8a518>

name: 
simple_rl_graph
top_level_manager: 
<rl_coach.level_manager.LevelManager object at 0x7fb67c6c1518>
reset_required: 
False
data_store: 
None
env_params: 
"GymVectorEnvironment" {
    "additional_simulator_parameters": {},
    "custom_reward_threshold": null,
    "default_input_filter": {
        "_observation_filters": {},
        "_reward_filters": {},
        "i_am_a_reference_filter": false,
        "name": "no_input_filter",
        "__class__": "NoInputFilter"
    },
    "default_output_filter": {
        "_action_filters": {},
        "i_am_a_reference_filter": false,
        "name": null,
        "__class__": "NoOutputFilter"
    },
    "experiment_path": "./experiments/hc_mujoco/17_01_2019-10_29",
    "frame_skip": 1,
    "human_control": false,
    "level": {
        "levels": {
            "ant": "Ant-v2",
            "half_cheetah": "HalfCheetah-v2",
            "hopper": "Hopper-v2",
            "humanoid": "Humanoid-v2",
            "humanoid_standup": "HumanoidStandup-v2",
            "inverted_double_pendulum": "InvertedDoublePendulum-v2",
            "inverted_pendulum": "InvertedPendulum-v2",
            "pusher": "Pusher-v2",
            "reacher": "Reacher-v2",
            "striker": "Striker-v2",
            "swimmer": "Swimmer-v2",
            "thrower": "Thrower-v2",
            "walker2d": "Walker2d-v2"
        },
        "selected_level": "half_cheetah",
        "__class__": "SingleLevelSelection"
    },
    "max_over_num_frames": 1,
    "observation_space_type": null,
    "random_initialization_steps": 0,
    "seed": null,
    "target_success_rate": 1.0
}

checkpoint_state_updater: 
None
agent_params: 
"ActorCriticAgentParameters" {
    "algorithm": {
        "act_for_full_episodes": false,
        "apply_gradients_every_x_episodes": 1,
        "beta_entropy": 0.0001,
        "discount": 0.99,
        "distributed_coach_synchronization_type": null,
        "estimate_state_value_using_gae": false,
        "gae_lambda": 0.96,
        "heatup_using_network_decisions": false,
        "in_action_space": null,
        "load_memory_from_file_path": null,
        "n_step": -1,
        "num_consecutive_playing_steps": {
            "_num_steps": 1,
            "__class__": "EnvironmentSteps"
        },
        "num_consecutive_training_steps": 1,
        "num_steps_between_copying_online_weights_to_target": {
            "_num_steps": 0,
            "__class__": "TrainingSteps"
        },
        "num_steps_between_gradient_updates": 10000000,
        "policy_gradient_rescaler": {
            "_name_": "A_VALUE",
            "_value_": 5,
            "__objclass__": "<enum 'PolicyGradientRescaler'>"
        },
        "rate_for_copying_weights_to_target": 1.0,
        "scale_external_reward_by_intrinsic_reward_value": false,
        "share_statistics_between_workers": true,
        "store_transitions_only_when_episodes_are_terminated": false,
        "use_accumulated_reward_as_measurement": false,
        "__class__": "ActorCriticAlgorithmParameters"
    },
    "current_episode": 0,
    "exploration": {
        "action_space": {
            "_high": "array([ 1.,  1.,  1.,  1.,  1.,  1.], dtype=float32)",
            "_low": "array([-1., -1., -1., -1., -1., -1.], dtype=float32)",
            "_shape": "array([6])",
            "default_action": "array([ 0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)",
            "descriptions": {},
            "max_abs_range": "array([ 1.,  1.,  1.,  1.,  1.,  1.], dtype=float32)",
            "num_dimensions": 1,
            "num_elements": 6,
            "__class__": "BoxActionSpace"
        },
        "evaluation_noise_percentage": 0.05,
        "noise_percentage_schedule": {
            "current_value": 0.1,
            "decay_delta": 0.0,
            "decay_steps": 50000,
            "final_value": 0.1,
            "initial_value": 0.1,
            "__class__": "LinearSchedule"
        },
        "__class__": "ContinuousEntropyParameters"
    },
    "full_name_id": "main_level/agent",
    "input_filter": {
        "_observation_filters": {
            "observation": {
                "normalize": {
                    "clip_max": 5.0,
                    "clip_min": -5.0,
                    "name": "observation_stats",
                    "observation_space": null,
                    "running_observation_stats": {
                        "_count": 0.01,
                        "_mean": "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n        0.,  0.,  0.,  0.])",
                        "_shape": "array([17])",
                        "_std": "array([ 0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,\n        0.1,  0.1,  0.1,  0.1,  0.1,  0.1])",
                        "_sum": "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n        0.,  0.,  0.,  0.])",
                        "_sum_squares": "array([ 0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,\n        0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01])",
                        "clip_values": [
                            -5.0,
                            5.0
                        ],
                        "epsilon": 0.01,
                        "name": "observation_stats",
                        "pubsub": null,
                        "__class__": "NumpySharedRunningStats"
                    },
                    "supports_batching": true,
                    "__class__": "ObservationNormalizationFilter"
                }
            }
        },
        "_reward_filters": {
            "rescale": {
                "name": null,
                "rescale_factor": 0.05,
                "__class__": "RewardRescaleFilter"
            }
        },
        "i_am_a_reference_filter": false,
        "name": "input_filter",
        "__class__": "InputFilter"
    },
    "is_a_highest_level_agent": true,
    "is_a_lowest_level_agent": true,
    "memory": {
        "load_memory_from_file_path": null,
        "shared_memory": false,
        "__class__": "SingleEpisodeBufferParameters"
    },
    "name": "agent",
    "network_wrappers": {
        "main": {
            "adam_optimizer_beta1": 0.9,
            "adam_optimizer_beta2": 0.99,
            "async_training": true,
            "batch_size": 32,
            "clip_gradients": 40.0,
            "create_target_network": false,
            "embedding_merger_type": {
                "_name_": "Concat",
                "_value_": 0,
                "__objclass__": "<enum 'EmbeddingMergerType'>"
            },
            "force_cpu": false,
            "framework": {
                "_name_": "tensorflow",
                "_value_": "TensorFlow",
                "__objclass__": "<enum 'Frameworks'>"
            },
            "gradients_clipping_method": {
                "_name_": "ClipByGlobalNorm",
                "_value_": 0,
                "__objclass__": "<enum 'GradientClippingMethod'>"
            },
            "heads_parameters": {
                "0": {
                    "activation_function": "relu",
                    "dense_layer": null,
                    "loss_weight": 0.5,
                    "name": "v_head_params",
                    "num_output_head_copies": 1,
                    "parameterized_class_name": "VHead",
                    "rescale_gradient_from_head_by_factor": 1.0,
                    "__class__": "VHeadParameters"
                },
                "1": {
                    "activation_function": "tanh",
                    "dense_layer": null,
                    "loss_weight": 1.0,
                    "name": "policy_head_params",
                    "num_output_head_copies": 1,
                    "parameterized_class_name": "PolicyHead",
                    "rescale_gradient_from_head_by_factor": 1.0,
                    "__class__": "PolicyHeadParameters"
                }
            },
            "input_embedders_parameters": {
                "observation": {
                    "activation_function": "relu",
                    "batchnorm": false,
                    "dense_layer": null,
                    "dropout_rate": 0.0,
                    "input_clipping": null,
                    "input_offset": {
                        "image": 0.0,
                        "tensor": 0.0,
                        "vector": 0.0
                    },
                    "input_rescaling": {
                        "image": 255.0,
                        "tensor": 1.0,
                        "vector": 1.0
                    },
                    "is_training": false,
                    "name": "embedder",
                    "scheme": {
                        "_name_": "Medium",
                        "_value_": "Medium",
                        "__objclass__": "<enum 'EmbedderScheme'>"
                    },
                    "__class__": "InputEmbedderParameters"
                }
            },
            "l2_regularization": 0,
            "learning_rate": 1e-05,
            "learning_rate_decay_rate": 0,
            "learning_rate_decay_steps": 0,
            "middleware_parameters": {
                "activation_function": "relu",
                "batchnorm": false,
                "dense_layer": null,
                "dropout_rate": 0.0,
                "is_training": false,
                "name": "middleware_fc_embedder",
                "parameterized_class_name": "FCMiddleware",
                "scheme": {
                    "_name_": "Medium",
                    "_value_": "Medium",
                    "__objclass__": "<enum 'MiddlewareScheme'>"
                },
                "__class__": "FCMiddlewareParameters"
            },
            "optimizer_epsilon": 0.0001,
            "optimizer_type": "Adam",
            "replace_mse_with_huber_loss": false,
            "rms_prop_optimizer_decay": 0.9,
            "scale_down_gradients_by_number_of_workers_for_sync_training": true,
            "sess": null,
            "shared_optimizer": true,
            "tensorflow_support": true,
            "use_separate_networks_per_head": false,
            "__class__": "ActorCriticNetworkParameters"
        }
    },
    "output_filter": {
        "_action_filters": {},
        "i_am_a_reference_filter": false,
        "name": "output_filter",
        "__class__": "NoOutputFilter"
    },
    "pre_network_filter": {
        "_observation_filters": {},
        "_reward_filters": {},
        "i_am_a_reference_filter": false,
        "name": "pre_network_filter",
        "__class__": "NoInputFilter"
    },
    "task_parameters": {
        "apply_stop_condition": false,
        "checkpoint_restore_dir": null,
        "checkpoint_save_dir": null,
        "checkpoint_save_secs": null,
        "evaluate_only": false,
        "experiment_path": "./experiments/hc_mujoco/17_01_2019-10_29",
        "export_onnx_graph": false,
        "framework_type": {
            "_name_": "tensorflow",
            "_value_": "TensorFlow",
            "__objclass__": "<enum 'Frameworks'>"
        },
        "num_gpu": 1,
        "seed": null,
        "task_index": 0,
        "use_cpu": false,
        "__class__": "TaskParameters"
    },
    "visualization": {
        "add_rendered_image_to_env_response": false,
        "dump_csv": true,
        "dump_gifs": false,
        "dump_in_episode_signals": false,
        "dump_mp4": false,
        "dump_parameters_documentation": true,
        "dump_signals_to_csv_every_x_episodes": 5,
        "max_fps_for_human_control": 10,
        "native_rendering": false,
        "print_networks_summary": false,
        "render": true,
        "tensorboard": false,
        "video_dump_filters": {
            "0": {
                "run_phases": {
                    "0": {
                        "_name_": "TEST",
                        "_value_": "Testing",
                        "__objclass__": "<enum 'RunPhase'>"
                    }
                },
                "__class__": "SelectedPhaseOnlyDumpFilter"
            },
            "1": {
                "max_reward_achieved": -Infinity,
                "__class__": "MaxDumpFilter"
            }
        },
        "__class__": "VisualizationParameters"
    }
}

level_managers: 
0: <rl_coach.level_manager.LevelManager object at 0x7fb67c6c1518>

environments: 
0: <rl_coach.environments.gym_environment.GymEnvironment object at 0x7fb68aa8a7f0>

graph_logger: 
<rl_coach.logger.Logger object at 0x7fb68aa8a710>
graph_creation_time: 
1547717376.892633
