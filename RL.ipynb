{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All this section consists in the implementation of the Mirror Descent with the relative entropy. This work is based on the paper \"A Unified View of Entropy-Regularized Markov Decision Processes\" with the pseudo code detailed in the paper \"Relative Entropy Policy Search\" from Jan Peters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRID RENDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class GUI(Canvas):\n",
    "    def __init__(self, master, *args, **kwargs):\n",
    "        Canvas.__init__(self, master=master, *args, **kwargs)\n",
    "\n",
    "\n",
    "def draw_square_q(polygon, x, y, q, actions, dim=50):\n",
    "    polygon.create_polygon([x, y, x + dim, y, x + dim, y + dim, x, y + dim], outline='black',\n",
    "                           fill='white', width=2)\n",
    "\n",
    "    font = ('Helvetica', '30', 'bold')\n",
    "\n",
    "    for i, a in enumerate(actions):\n",
    "        if a == 0:\n",
    "            polygon.create_polygon([x + dim, y, x + dim / 2., y + dim / 2., x + dim, y + dim], outline='gray',\n",
    "                                   fill='red', width=2)\n",
    "            polygon.create_text(x + 3 * dim / 4., y + dim / 2., font=font, text=\"{:.3f}\".format(q[i]), anchor='center')\n",
    "        elif a == 1:\n",
    "            polygon.create_polygon([x, y + dim, x + dim / 2., y + dim / 2., x + dim, y + dim], outline='gray',\n",
    "                                   fill='green', width=2)\n",
    "            polygon.create_text(x + dim / 2., y + 3 * dim / 4., font=font, text=\"{:.3f}\".format(q[i]), anchor='n')\n",
    "        elif a == 2:\n",
    "            polygon.create_polygon([x, y, x + dim / 2., y + dim / 2., x, y + dim], outline='gray',\n",
    "                                   fill='yellow', width=2)\n",
    "            polygon.create_text(x + dim / 4., y + dim / 2., font=font, text=\"{:.3f}\".format(q[i]), anchor='center')\n",
    "        elif a == 3:\n",
    "            polygon.create_polygon([x + dim, y, x + dim / 2., y + dim / 2., x, y], outline='gray',\n",
    "                                   fill='purple', width=2)\n",
    "            polygon.create_text(x + dim / 2., y + dim / 4., font=font, text=\"{:.3f}\".format(q[i]), anchor='s')\n",
    "\n",
    "\n",
    "def draw_square_policy(w, x, y, pol, actions, dim=50):\n",
    "    w.create_polygon([x, y, x + dim, y, x + dim, y + dim, x, y + dim], outline='black',\n",
    "                     fill='white', width=2)\n",
    "\n",
    "    font = ('Helvetica', '30', 'bold')\n",
    "    if (hasattr(pol, \"size\") and pol.size > 1) or isinstance(pol, list):\n",
    "        d = pol\n",
    "    else:\n",
    "        d = [-1] * len(actions)\n",
    "        idx = actions.index(pol)\n",
    "        d[idx] = 1\n",
    "\n",
    "    for j, v in enumerate(d):\n",
    "        if j < len(actions):\n",
    "            a = actions[j]\n",
    "            if a == 0 and v > 0:\n",
    "                w.create_line(x + dim / 2., y + dim / 2., x + 3*dim / 4., y + dim / 2., tags=(\"line\",), arrow=\"last\")\n",
    "                if not np.isclose(v, 1.):\n",
    "                    w.create_text(x + 3*dim / 4., y + dim / 2., font=font, text=\"{:.1f}\".format(v), anchor='w')\n",
    "            elif a == 1 and v > 0:\n",
    "                w.create_line(x + dim / 2., y + dim / 2., x + dim / 2., y + 3* dim / 4., tags=(\"line\",), arrow=\"last\")\n",
    "                if not np.isclose(v, 1.):\n",
    "                    w.create_text(x + dim / 2., y + 3*dim / 4., font=font, text=\"{:.1f}\".format(v), anchor='n')\n",
    "            elif a == 2 and v >0:\n",
    "                w.create_line(x + dim / 2., y + dim / 2., x+dim/4., y + dim/2., tags=(\"line\",), arrow=\"last\")\n",
    "                if not np.isclose(v, 1.):\n",
    "                    w.create_text(x + dim / 4., y + dim / 2., font=font, text=\"{:.1f}\".format(v), anchor='e')\n",
    "            elif a == 3 and v >0:\n",
    "                w.create_line(x + dim / 2., y + dim / 2., x + dim / 2., y + dim / 4., tags=(\"line\",), arrow=\"last\")\n",
    "                if not np.isclose(v, 1.):\n",
    "                    w.create_text(x + dim / 2., y + dim / 4., font=font, text=\"{:.1f}\".format(v), anchor='s')\n",
    "\n",
    "\n",
    "def render_q(env, q):\n",
    "    root = Tk()\n",
    "    w = GUI(root)\n",
    "    rows, cols = len(env.grid), max(map(len, env.grid))\n",
    "    dim = 200\n",
    "    w.config(width=cols * (dim + 12), height=rows * (dim + 12))\n",
    "    for s in range(env.n_states):\n",
    "        r, c = env.state2coord[s]\n",
    "        draw_square_q(w, 10 + c * (dim + 4), 10 + r * (dim + 4), dim=dim, q=q[s],\n",
    "                      actions=env.state_actions[s])\n",
    "        w.pack()\n",
    "    w.pack()\n",
    "    root.mainloop()\n",
    "\n",
    "\n",
    "def render_policy(env, d):\n",
    "    root = Tk()\n",
    "    w = GUI(root)\n",
    "    rows, cols = len(env.grid), max(map(len, env.grid))\n",
    "    dim = 200\n",
    "    w.config(width=cols * (dim + 12), height=rows * (dim + 12))\n",
    "    for s in range(env.n_states):\n",
    "        r, c = env.state2coord[s]\n",
    "        draw_square_policy(w, 10 + c * (dim + 4), 10 + r * (dim + 4), dim=dim, pol=d[s],\n",
    "                           actions=[i for i in range(env.n_states)])\n",
    "        w.pack()\n",
    "    w.pack()\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRID WORLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numbers\n",
    "from tkinter import Tk\n",
    "import tkinter.font as tkFont\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "class GridWorld:\n",
    "    def __init__(self, gamma=0.95, grid=None, render=False):\n",
    "        self.grid = grid\n",
    "\n",
    "        self.action_names = np.array(['right', 'down', 'left', 'up'])\n",
    "\n",
    "        self.n_rows, self.n_cols = len(self.grid), max(map(len, self.grid))\n",
    "\n",
    "        # Create a map to translate coordinates [r,c] to scalar index\n",
    "        # (i.e., state) and vice-versa\n",
    "        self.coord2state = np.empty_like(self.grid, dtype=np.int)\n",
    "        self.n_states = 0\n",
    "        self.n_actions = 4\n",
    "        self.state2coord = []\n",
    "        for i in range(self.n_rows):\n",
    "            for j in range(len(self.grid[i])):\n",
    "                if self.grid[i][j] != 'x':\n",
    "                    self.coord2state[i, j] = self.n_states\n",
    "                    self.n_states += 1\n",
    "                    self.state2coord.append([i, j])\n",
    "                else:\n",
    "                    self.coord2state[i, j] = -1\n",
    "\n",
    "        # compute the actions available in each state\n",
    "        self.compute_available_actions()\n",
    "        self.gamma = gamma\n",
    "        self.proba_succ = 0.9\n",
    "        self.render = render\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            An initial state randomly drawn from\n",
    "            the initial distribution\n",
    "        \"\"\"\n",
    "        n_states = self.n_states\n",
    "        u = 0.9\n",
    "        a = np.zeros((n_states,))\n",
    "        a[0] = 0.5\n",
    "        a[3] = -0.8\n",
    "        u = np.power(np.ones((n_states,)) + a, u)\n",
    "        p = np.exp(u) / np.sum(np.exp(u))\n",
    "        x_0 = np.random.choice(np.arange(n_states), p=p)\n",
    "        return x_0\n",
    "\n",
    "    def step(self, state, action):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            state (int): the amount of good\n",
    "            action (int): the action to be executed\n",
    "\n",
    "        Returns:\n",
    "            next_state (int): the state reached by performing the action\n",
    "            reward (float): a scalar value representing the immediate reward\n",
    "            absorb (boolean): True if the next_state is absorsing, False otherwise\n",
    "        \"\"\"\n",
    "        r, c = self.state2coord[state]\n",
    "        #assert action in self.state_actions[state]\n",
    "        if isinstance(self.grid[r][c], numbers.Number):\n",
    "            return state, 0, True\n",
    "        else:\n",
    "            failed = np.random.rand(1) > self.proba_succ\n",
    "            if action == 0:\n",
    "                c = min(self.n_cols - 1, c + 1) if not failed else max(0, c - 1)\n",
    "            elif action == 1:\n",
    "                r = min(self.n_rows - 1, r + 1) if not failed else max(0, r - 1)\n",
    "            elif action == 2:\n",
    "                c = max(0, c - 1) if not failed else min(self.n_cols - 1, c + 1)\n",
    "            elif action == 3:\n",
    "                r = max(0, r - 1) if not failed else min(self.n_rows - 1, r + 1)\n",
    "\n",
    "            if self.grid[r][c] == 'x':\n",
    "                next_state = state\n",
    "                r, c = self.state2coord[next_state]\n",
    "            elif action not in self.state_actions[state]:\n",
    "                next_state = state\n",
    "                r, c = self.state2coord[next_state]\n",
    "            else:\n",
    "                next_state = self.coord2state[r, c]\n",
    "            if isinstance(self.grid[r][c], numbers.Number):\n",
    "                reward = self.grid[r][c]\n",
    "                absorb = True\n",
    "            else:\n",
    "                reward = 0.\n",
    "                absorb = False\n",
    "\n",
    "        if self.render:\n",
    "            self.show(state, action, next_state, reward)\n",
    "\n",
    "        return next_state, reward, absorb\n",
    "\n",
    "    def show(self, state, action, next_state, reward):\n",
    "        dim = 200\n",
    "        rows, cols = len(self.grid) + 0.5, max(map(len, self.grid))\n",
    "        if not hasattr(self, 'window'):\n",
    "            root = Tk()\n",
    "            self.window = GUI(root)\n",
    "\n",
    "            self.window.config(width=cols * (dim + 12), height=rows * (dim + 12))\n",
    "            my_font = tkFont.Font(family=\"Arial\", size=32, weight=\"bold\")\n",
    "            for s in range(self.n_states):\n",
    "                r, c = self.state2coord[s]\n",
    "                x, y = 10 + c * (dim + 4), 10 + r * (dim + 4)\n",
    "                if isinstance(self.grid[r][c], numbers.Number):\n",
    "                    self.window.create_polygon([x, y, x + dim, y, x + dim, y + dim, x, y + dim], outline='black',\n",
    "                                               fill='blue', width=2)\n",
    "                    self.window.create_text(x + dim / 2., y + dim / 2., text=\"{:.1f}\".format(self.grid[r][c]),\n",
    "                                            font=my_font, fill='white')\n",
    "                else:\n",
    "                    self.window.create_polygon([x, y, x + dim, y, x + dim, y + dim, x, y + dim], outline='black',\n",
    "                                               fill='white', width=2)\n",
    "            self.window.pack()\n",
    "\n",
    "        my_font = tkFont.Font(family=\"Arial\", size=32, weight=\"bold\")\n",
    "\n",
    "        r0, c0 = self.state2coord[state]\n",
    "        r0, c0 = 10 + c0 * (dim + 4), 10 + r0 * (dim + 4)\n",
    "        x0, y0 = r0 + dim / 2., c0 + dim / 2.\n",
    "        r1, c1 = self.state2coord[next_state]\n",
    "        r1, c1 = 10 + c1 * (dim + 4), 10 + r1 * (dim + 4)\n",
    "        x1, y1 = r1 + dim / 2., c1 + dim / 2.\n",
    "\n",
    "        if hasattr(self, 'oval2'):\n",
    "            # self.window.delete(self.line1)\n",
    "            # self.window.delete(self.oval1)\n",
    "            self.window.delete(self.oval2)\n",
    "            self.window.delete(self.text1)\n",
    "            self.window.delete(self.text2)\n",
    "\n",
    "        # self.line1 = self.window.create_arc(x0, y0, x1, y1, dash=(3,5))\n",
    "        # self.oval1 = self.window.create_oval(x0 - dim / 20., y0 - dim / 20., x0 + dim / 20., y0 + dim / 20., dash=(3,5))\n",
    "        self.oval2 = self.window.create_oval(x1 - dim / 5., y1 - dim / 5., x1 + dim / 5., y1 + dim / 5., fill='red')\n",
    "        self.text1 = self.window.create_text(dim, (rows - 0.25) * (dim + 12), font=my_font,\n",
    "                                             text=\"r= {:.1f}\".format(reward), anchor='center')\n",
    "        self.text2 = self.window.create_text(2 * dim, (rows - 0.25) * (dim + 12), font=my_font,\n",
    "                                             text=\"action: {}\".format(self.action_names[action]), anchor='center')\n",
    "        self.window.update()\n",
    "\n",
    "    def compute_available_actions(self):\n",
    "        # define available actions in each state\n",
    "        # actions are indexed by: 0=right, 1=down, 2=left, 3=up\n",
    "        self.state_actions = []\n",
    "        for i in range(self.n_rows):\n",
    "            for j in range(self.n_cols):\n",
    "                if isinstance(self.grid[i][j], numbers.Number):\n",
    "                    self.state_actions.append([0])\n",
    "                elif self.grid[i][j] != 'x':\n",
    "                    actions = [0, 1, 2, 3]\n",
    "                    if i == 0:\n",
    "                        actions.remove(3)\n",
    "                    if j == self.n_cols - 1:\n",
    "                        actions.remove(0)\n",
    "                    if i == self.n_rows - 1:\n",
    "                        actions.remove(1)\n",
    "                    if j == 0:\n",
    "                        actions.remove(2)\n",
    "\n",
    "                    for a in copy.copy(actions):\n",
    "                        r, c = i, j\n",
    "                        if a == 0:\n",
    "                            c = min(self.n_cols - 1, c + 1)\n",
    "                        elif a == 1:\n",
    "                            r = min(self.n_rows - 1, r + 1)\n",
    "                        elif a == 2:\n",
    "                            c = max(0, c - 1)\n",
    "                        else:\n",
    "                            r = max(0, r - 1)\n",
    "                        if self.grid[r][c] == 'x':\n",
    "                            actions.remove(a)\n",
    "\n",
    "                    self.state_actions.append(actions)\n",
    "\n",
    "\n",
    "grid1 = [\n",
    "    ['', '', '', 1],\n",
    "    ['', 'x', '', -1],\n",
    "    ['', '', '', '']\n",
    "]\n",
    "env = GridWorld(gamma=0.95, grid=grid1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.optimize as opt\n",
    "import pdb\n",
    "\n",
    "def collect_episodes(mdp, policy=None, horizon=None, n_episodes=1, render=False):\n",
    "    paths = []\n",
    "\n",
    "    for _ in range(n_episodes):\n",
    "        observations = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        next_states = []\n",
    "\n",
    "        state = mdp.reset()\n",
    "        for _ in range(horizon):\n",
    "            action = policy.draw_action(state)\n",
    "            next_state, reward, terminal = mdp.step(state,action)\n",
    "            if render:\n",
    "                mdp.render()\n",
    "            observations.append(state)\n",
    "            actions.append(action)\n",
    "            rewards.append(reward)\n",
    "            next_states.append(next_state)\n",
    "            state = copy.copy(next_state)\n",
    "            if terminal:\n",
    "                # Finish rollout if terminal state reached\n",
    "                break\n",
    "                # We need to compute the empirical return for each time step along the\n",
    "                # trajectory\n",
    "\n",
    "        paths.append(dict(\n",
    "            states=np.array(observations),\n",
    "            actions=np.array(actions),\n",
    "            rewards=np.array(rewards),\n",
    "            next_states=np.array(next_states)\n",
    "        ))\n",
    "    return paths\n",
    "\n",
    "def compute_new_policy(eta,policy,phi,theta,samples):\n",
    "    log_new_pi = np.zeros((policy.n_states,policy.n_actions))\n",
    "    A = np.zeros((policy.n_states,policy.n_actions))\n",
    "    counter = np.zeros((policy.n_states,policy.n_actions))\n",
    "    nb_samples = 0\n",
    "    for i in range(len(samples)):\n",
    "        states = samples[i]['states']\n",
    "        actions = samples[i]['actions']\n",
    "        rewards = samples[i]['rewards']\n",
    "        next_states = samples[i]['next_states']\n",
    "\n",
    "        for j in range(len(states)):\n",
    "            A[states[j],actions[j]] += rewards[j] + np.dot(phi[next_states[j],:],theta) - np.dot(phi[states[j],:],theta)\n",
    "            counter[states[j],actions[j]] += 1\n",
    "            nb_samples += 1\n",
    "    for s in range(env.n_states):\n",
    "        for a in range(env.n_actions):\n",
    "            if counter[s,a]!=0:\n",
    "                A[s,a] /= counter[s,a]\n",
    "    for s in range(policy.n_states):\n",
    "        for a in range(policy.n_actions):\n",
    "            argexpo = np.zeros(policy.n_actions)\n",
    "            if policy.pi[s,a] == 0:\n",
    "                log_new_pi[s,a] = -float('inf')\n",
    "            else:\n",
    "                for b in range(policy.n_actions):\n",
    "                    argexpo[b] = np.log(policy.pi[s,b]+0.0001) + eta * A[s,b]\n",
    "                maxi = np.max(argexpo)\n",
    "                log_new_pi[s,a] = argexpo[a] - np.log(np.sum(np.exp(argexpo - maxi))) - maxi\n",
    "    print(np.exp(log_new_pi))\n",
    "    return(Policy(np.exp(log_new_pi)))\n",
    "\n",
    "\n",
    "def g(theta,eta,phi,samples):\n",
    "    res = 0\n",
    "    A = np.zeros((env.n_states,env.n_actions))\n",
    "    counter = np.zeros((env.n_states,env.n_actions))\n",
    "    nb_samples = 0\n",
    "    for i in range(len(samples)):\n",
    "        states = samples[i]['states']\n",
    "        actions = samples[i]['actions']\n",
    "        rewards = samples[i]['rewards']\n",
    "        next_states = samples[i]['next_states']\n",
    "\n",
    "        for j in range(len(states)):\n",
    "            A[states[j],actions[j]] += rewards[j] + np.dot(phi[next_states[j],:],theta) - np.dot(phi[states[j],:],theta)\n",
    "            counter[states[j],actions[j]] += 1\n",
    "            nb_samples += 1\n",
    "    for s in range(env.n_states):\n",
    "        for a in range(env.n_actions):\n",
    "            if counter[s,a]!=0:\n",
    "                A[s,a] /= counter[s,a]\n",
    "    for i in range(len(samples)):\n",
    "        states = samples[i]['states']\n",
    "        actions = samples[i]['actions']\n",
    "        for j in range(len(states)):\n",
    "            res += np.exp(eta*A[states[j],actions[j]])\n",
    "    res /= nb_samples\n",
    "    return (np.log(res)/eta)\n",
    "\n",
    "def Dg(theta,eta,phi,samples):\n",
    "    n_states,p = np.shape(phi)\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    A = np.zeros((env.n_states,env.n_actions))\n",
    "    D = np.zeros((env.n_states,env.n_actions,p))\n",
    "    counter = np.zeros((env.n_states,env.n_actions))\n",
    "    for i in range(len(samples)):\n",
    "        states = samples[i]['states']\n",
    "        actions = samples[i]['actions']\n",
    "        rewards = samples[i]['rewards']\n",
    "        next_states = samples[i]['next_states']\n",
    "\n",
    "        for j in range(len(states)):\n",
    "            A[states[j],actions[j]] += rewards[j] + np.dot(phi[next_states[j],:],theta) - np.dot(phi[states[j],:],theta)\n",
    "            D[states[j],actions[j],:] += phi[next_states[j],:] - phi[states[j],:]\n",
    "            counter[states[j],actions[j]] += 1\n",
    "    for s in range(env.n_states):\n",
    "        for a in range(env.n_actions):\n",
    "            if counter[s,a]!=0:\n",
    "                A[s,a] /= counter[s,a]\n",
    "    for s in range(env.n_states):\n",
    "        for a in range(env.n_actions):\n",
    "            if counter[s,a]!=0:\n",
    "                D[s,a,:] /= counter[s,a]\n",
    "    for i in range(len(samples)):\n",
    "        states = samples[i]['states']\n",
    "        actions = samples[i]['actions']\n",
    "        for j in range(len(states)):\n",
    "            numerator += np.exp(eta*A[states[j],actions[j]]) * D[states[j],actions[j]]\n",
    "            denominator += np.exp(eta*A[states[j],actions[j]])\n",
    "    return ((1/eta) * numerator / denominator)\n",
    "\n",
    "\n",
    "class Policy(object):\n",
    "    def __init__(self,pi):\n",
    "        n_states,n_actions = np.shape(pi)\n",
    "        self.n_actions = n_actions\n",
    "        self.n_states = n_states\n",
    "        self.pi = pi\n",
    "    def draw_action(self,state):\n",
    "        u = np.random.rand()\n",
    "        probas = np.cumsum(self.pi[state,:])\n",
    "        a = 0\n",
    "        while (a < self.n_actions-1 and (u > probas[a] or self.pi[state,a]==0)):\n",
    "            a += 1\n",
    "        return a\n",
    "\n",
    "def compute_phi(env,p):\n",
    "    phi = np.zeros((env.n_states,p))\n",
    "    for k in range(env.n_states):\n",
    "        phi[k,:] = [k,k**2,np.log(k+1)]\n",
    "    return(phi)\n",
    "    \n",
    "def initialize_pi(env):\n",
    "    pi = np.zeros((env.n_states,env.n_actions))\n",
    "    for s in range(env.n_states):\n",
    "        actions = env.state_actions[s]\n",
    "        for a in actions:\n",
    "            pi[s,a] = 1./len(actions)\n",
    "    return(pi)\n",
    "    \n",
    "    \n",
    "def REPS_mirror_descent(env):\n",
    "    \"\"\"Relative Entropy Policy Search using Mirror Descent\"\"\"\n",
    "    p = 3    \n",
    "    # initialization of the distribution\n",
    "    pi = initialize_pi(env)\n",
    "    policy = Policy(pi)\n",
    "    #Tmax =  -100*np.log(10e-6)/(1-env.gamma)\n",
    "    K = 50\n",
    "    N = 100\n",
    "    eta = 0.1\n",
    "    theta = [0 for i in range(p)]\n",
    "    phi = compute_phi(env,p)\n",
    "    for k in range(K):\n",
    "        print('Iteration nÂ°',k)\n",
    "        ##### SAMPLING\n",
    "        samples = collect_episodes(env,policy=policy,horizon=100,n_episodes=N)\n",
    "        \n",
    "        #### OPTIMIZE\n",
    "        theta = opt.fmin_bfgs(g,x0=theta,fprime=Dg,args=(eta,phi,samples))\n",
    "        \n",
    "        #### COMPUTE THE NEW POLICY\n",
    "        policy = compute_new_policy(eta,policy,phi,theta,samples)   \n",
    "    return(policy,theta,phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5        0.5        0.         0.        ]\n",
      " [0.5        0.         0.5        0.        ]\n",
      " [0.33333333 0.33333333 0.33333333 0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.         0.5        0.         0.5       ]\n",
      " [0.33333333 0.33333333 0.         0.33333333]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.5        0.         0.         0.5       ]\n",
      " [0.5        0.         0.5        0.        ]\n",
      " [0.33333333 0.         0.33333333 0.33333333]\n",
      " [0.         0.         0.5        0.5       ]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.029215\n",
      "         Iterations: 56\n",
      "         Function evaluations: 110\n",
      "         Gradient evaluations: 110\n",
      "[[0.52747138 0.47231955 0.         0.        ]\n",
      " [0.49411275 0.         0.50568233 0.        ]\n",
      " [0.35135484 0.30260066 0.34594472 0.        ]\n",
      " [0.99970012 0.         0.         0.        ]\n",
      " [0.         0.47593022 0.         0.52387847]\n",
      " [0.29109291 0.35125458 0.         0.35755594]\n",
      " [0.99970012 0.         0.         0.        ]\n",
      " [0.50232947 0.         0.         0.49747514]\n",
      " [0.51714663 0.         0.48265548 0.        ]\n",
      " [0.35739992 0.         0.3262506  0.31624778]\n",
      " [0.         0.         0.54076223 0.45900674]]\n",
      "ok\n",
      "[[0.52747138 0.47231955 0.         0.        ]\n",
      " [0.49411275 0.         0.50568233 0.        ]\n",
      " [0.35135484 0.30260066 0.34594472 0.        ]\n",
      " [0.99970012 0.         0.         0.        ]\n",
      " [0.         0.47593022 0.         0.52387847]\n",
      " [0.29109291 0.35125458 0.         0.35755594]\n",
      " [0.99970012 0.         0.         0.        ]\n",
      " [0.50232947 0.         0.         0.49747514]\n",
      " [0.51714663 0.         0.48265548 0.        ]\n",
      " [0.35739992 0.         0.3262506  0.31624778]\n",
      " [0.         0.         0.54076223 0.45900674]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.014914\n",
      "         Iterations: 48\n",
      "         Function evaluations: 153\n",
      "         Gradient evaluations: 145\n",
      "[[0.53776246 0.46202698 0.         0.        ]\n",
      " [0.48145633 0.         0.51834493 0.        ]\n",
      " [0.36666376 0.28869594 0.34454393 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.47140627 0.         0.52840791]\n",
      " [0.2601109  0.38507977 0.         0.35471298]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.52504659 0.         0.         0.47475251]\n",
      " [0.5378827  0.         0.46191983 0.        ]\n",
      " [0.38927961 0.         0.32286913 0.28774763]\n",
      " [0.         0.         0.59213757 0.40762962]]\n",
      "ok\n",
      "[[0.53776246 0.46202698 0.         0.        ]\n",
      " [0.48145633 0.         0.51834493 0.        ]\n",
      " [0.36666376 0.28869594 0.34454393 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.47140627 0.         0.52840791]\n",
      " [0.2601109  0.38507977 0.         0.35471298]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.52504659 0.         0.         0.47475251]\n",
      " [0.5378827  0.         0.46191983 0.        ]\n",
      " [0.38927961 0.         0.32286913 0.28774763]\n",
      " [0.         0.         0.59213757 0.40762962]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.032402\n",
      "         Iterations: 50\n",
      "         Function evaluations: 96\n",
      "         Gradient evaluations: 96\n",
      "[[0.56142828 0.43836291 0.         0.        ]\n",
      " [0.47414493 0.         0.52565137 0.        ]\n",
      " [0.3834224  0.2628899  0.35358911 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.45084916 0.         0.54896338]\n",
      " [0.2235029  0.41215692 0.         0.36424621]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.53745658 0.         0.         0.46234678]\n",
      " [0.55718367 0.         0.44261931 0.        ]\n",
      " [0.42522849 0.         0.31756979 0.25709995]\n",
      " [0.         0.         0.64202981 0.35773547]]\n",
      "ok\n",
      "[[0.56142828 0.43836291 0.         0.        ]\n",
      " [0.47414493 0.         0.52565137 0.        ]\n",
      " [0.3834224  0.2628899  0.35358911 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.45084916 0.         0.54896338]\n",
      " [0.2235029  0.41215692 0.         0.36424621]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.53745658 0.         0.         0.46234678]\n",
      " [0.55718367 0.         0.44261931 0.        ]\n",
      " [0.42522849 0.         0.31756979 0.25709995]\n",
      " [0.         0.         0.64202981 0.35773547]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.006121\n",
      "         Iterations: 52\n",
      "         Function evaluations: 102\n",
      "         Gradient evaluations: 102\n",
      "[[0.57352286 0.42626637 0.         0.        ]\n",
      " [0.46287871 0.         0.53692254 0.        ]\n",
      " [0.39804601 0.24882869 0.35302886 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.44177876 0.         0.55803432]\n",
      " [0.20000496 0.43882778 0.         0.3610719 ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.55446495 0.         0.         0.44533541]\n",
      " [0.57397852 0.         0.42582336 0.        ]\n",
      " [0.45369488 0.         0.31219967 0.23400355]\n",
      " [0.         0.         0.6801477  0.31962991]]\n",
      "ok\n",
      "[[0.57352286 0.42626637 0.         0.        ]\n",
      " [0.46287871 0.         0.53692254 0.        ]\n",
      " [0.39804601 0.24882869 0.35302886 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.44177876 0.         0.55803432]\n",
      " [0.20000496 0.43882778 0.         0.3610719 ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.55446495 0.         0.         0.44533541]\n",
      " [0.57397852 0.         0.42582336 0.        ]\n",
      " [0.45369488 0.         0.31219967 0.23400355]\n",
      " [0.         0.         0.6801477  0.31962991]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.026702\n",
      "         Iterations: 59\n",
      "         Function evaluations: 115\n",
      "         Gradient evaluations: 115\n",
      "[[0.60545518 0.39433047 0.         0.        ]\n",
      " [0.4494337  0.         0.55036335 0.        ]\n",
      " [0.41076954 0.22448342 0.36464887 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.40905852 0.         0.59075648]\n",
      " [0.16956558 0.45349055 0.         0.37685064]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.55923056 0.         0.         0.44057389]\n",
      " [0.59136222 0.         0.40844187 0.        ]\n",
      " [0.48756952 0.         0.30068063 0.21165001]\n",
      " [0.         0.         0.72151528 0.27825645]]\n",
      "ok\n",
      "[[0.60545518 0.39433047 0.         0.        ]\n",
      " [0.4494337  0.         0.55036335 0.        ]\n",
      " [0.41076954 0.22448342 0.36464887 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.40905852 0.         0.59075648]\n",
      " [0.16956558 0.45349055 0.         0.37685064]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.55923056 0.         0.         0.44057389]\n",
      " [0.59136222 0.         0.40844187 0.        ]\n",
      " [0.48756952 0.         0.30068063 0.21165001]\n",
      " [0.         0.         0.72151528 0.27825645]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.003545\n",
      "         Iterations: 52\n",
      "         Function evaluations: 104\n",
      "         Gradient evaluations: 104\n",
      "[[0.61651271 0.38327653 0.         0.        ]\n",
      " [0.43715973 0.         0.56264243 0.        ]\n",
      " [0.4263987  0.21002118 0.36348423 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.3972183  0.         0.60259426]\n",
      " [0.15000381 0.47480935 0.         0.37509077]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.57154112 0.         0.         0.42825946]\n",
      " [0.60479102 0.         0.39501098 0.        ]\n",
      " [0.51105182 0.         0.29310802 0.19573946]\n",
      " [0.         0.         0.75115132 0.24863115]]\n",
      "ok\n",
      "[[0.61651271 0.38327653 0.         0.        ]\n",
      " [0.43715973 0.         0.56264243 0.        ]\n",
      " [0.4263987  0.21002118 0.36348423 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.3972183  0.         0.60259426]\n",
      " [0.15000381 0.47480935 0.         0.37509077]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.57154112 0.         0.         0.42825946]\n",
      " [0.60479102 0.         0.39501098 0.        ]\n",
      " [0.51105182 0.         0.29310802 0.19573946]\n",
      " [0.         0.         0.75115132 0.24863115]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.009418\n",
      "         Iterations: 55\n",
      "         Function evaluations: 200\n",
      "         Gradient evaluations: 189\n",
      "[[0.63143329 0.3683537  0.         0.        ]\n",
      " [0.42130738 0.         0.57849491 0.        ]\n",
      " [0.44169568 0.19502939 0.36317859 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.37737063 0.         0.62244268]\n",
      " [0.13163574 0.48923788 0.         0.3790298 ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.57860462 0.         0.         0.4211968 ]\n",
      " [0.61420113 0.         0.3856011  0.        ]\n",
      " [0.52777199 0.         0.287088   0.18503987]\n",
      " [0.         0.         0.77596053 0.22382594]]\n",
      "ok\n",
      "[[0.63143329 0.3683537  0.         0.        ]\n",
      " [0.42130738 0.         0.57849491 0.        ]\n",
      " [0.44169568 0.19502939 0.36317859 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.37737063 0.         0.62244268]\n",
      " [0.13163574 0.48923788 0.         0.3790298 ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.57860462 0.         0.         0.4211968 ]\n",
      " [0.61420113 0.         0.3856011  0.        ]\n",
      " [0.52777199 0.         0.287088   0.18503987]\n",
      " [0.         0.         0.77596053 0.22382594]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.007284\n",
      "         Iterations: 46\n",
      "         Function evaluations: 127\n",
      "         Gradient evaluations: 117\n",
      "[[0.63820398 0.36158549 0.         0.        ]\n",
      " [0.40774988 0.         0.59205398 0.        ]\n",
      " [0.45838951 0.18520345 0.3563117  0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.3696096  0.         0.63020313]\n",
      " [0.11704902 0.51441778 0.         0.36843733]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.59385172 0.         0.         0.40594832]\n",
      " [0.62590741 0.         0.37389473 0.        ]\n",
      " [0.5494676  0.         0.28088842 0.16954342]\n",
      " [0.         0.         0.80489696 0.19488742]]\n",
      "ok\n",
      "[[0.63820398 0.36158549 0.         0.        ]\n",
      " [0.40774988 0.         0.59205398 0.        ]\n",
      " [0.45838951 0.18520345 0.3563117  0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.3696096  0.         0.63020313]\n",
      " [0.11704902 0.51441778 0.         0.36843733]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.59385172 0.         0.         0.40594832]\n",
      " [0.62590741 0.         0.37389473 0.        ]\n",
      " [0.5494676  0.         0.28088842 0.16954342]\n",
      " [0.         0.         0.80489696 0.19488742]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.011678\n",
      "         Iterations: 54\n",
      "         Function evaluations: 152\n",
      "         Gradient evaluations: 142\n",
      "[[0.66341332 0.33636699 0.         0.        ]\n",
      " [0.38453382 0.         0.61526779 0.        ]\n",
      " [0.46963868 0.16773144 0.36253346 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.34200114 0.         0.65782   ]\n",
      " [0.1004566  0.53102988 0.         0.36842086]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.60498887 0.         0.         0.394814  ]\n",
      " [0.64128823 0.         0.35851467 0.        ]\n",
      " [0.57737607 0.         0.26938521 0.15313905]\n",
      " [0.         0.         0.83346103 0.16631929]]\n",
      "ok\n",
      "[[0.66341332 0.33636699 0.         0.        ]\n",
      " [0.38453382 0.         0.61526779 0.        ]\n",
      " [0.46963868 0.16773144 0.36253346 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.34200114 0.         0.65782   ]\n",
      " [0.1004566  0.53102988 0.         0.36842086]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.60498887 0.         0.         0.394814  ]\n",
      " [0.64128823 0.         0.35851467 0.        ]\n",
      " [0.57737607 0.         0.26938521 0.15313905]\n",
      " [0.         0.         0.83346103 0.16631929]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.003139\n",
      "         Iterations: 59\n",
      "         Function evaluations: 116\n",
      "         Gradient evaluations: 116\n",
      "[[0.68194667 0.31783673 0.         0.        ]\n",
      " [0.36558957 0.         0.63421361 0.        ]\n",
      " [0.48296351 0.15294515 0.36399536 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.31791937 0.         0.68189826]\n",
      " [0.08667242 0.54206442 0.         0.37116818]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.61208845 0.         0.         0.38771368]\n",
      " [0.6526118  0.         0.34719078 0.        ]\n",
      " [0.59533743 0.         0.26222462 0.14233858]\n",
      " [0.         0.         0.85236704 0.14742014]]\n",
      "ok\n",
      "[[0.68194667 0.31783673 0.         0.        ]\n",
      " [0.36558957 0.         0.63421361 0.        ]\n",
      " [0.48296351 0.15294515 0.36399536 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.31791937 0.         0.68189826]\n",
      " [0.08667242 0.54206442 0.         0.37116818]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.61208845 0.         0.         0.38771368]\n",
      " [0.6526118  0.         0.34719078 0.        ]\n",
      " [0.59533743 0.         0.26222462 0.14233858]\n",
      " [0.         0.         0.85236704 0.14742014]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.001752\n",
      "         Iterations: 52\n",
      "         Function evaluations: 139\n",
      "         Gradient evaluations: 130\n",
      "[[0.68243439 0.31735585 0.         0.        ]\n",
      " [0.35323728 0.         0.6465676  0.        ]\n",
      " [0.50005296 0.14909888 0.35075403 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.32328896 0.         0.6765237 ]\n",
      " [0.07654928 0.5804497  0.         0.34290762]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.63884451 0.         0.         0.36095437]\n",
      " [0.66867193 0.         0.33113128 0.        ]\n",
      " [0.62185499 0.         0.25349635 0.12454825]\n",
      " [0.         0.         0.87164369 0.12814189]]\n",
      "ok\n",
      "[[0.68243439 0.31735585 0.         0.        ]\n",
      " [0.35323728 0.         0.6465676  0.        ]\n",
      " [0.50005296 0.14909888 0.35075403 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.32328896 0.         0.6765237 ]\n",
      " [0.07654928 0.5804497  0.         0.34290762]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.63884451 0.         0.         0.36095437]\n",
      " [0.66867193 0.         0.33113128 0.        ]\n",
      " [0.62185499 0.         0.25349635 0.12454825]\n",
      " [0.         0.         0.87164369 0.12814189]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000643\n",
      "         Iterations: 57\n",
      "         Function evaluations: 147\n",
      "         Gradient evaluations: 137\n",
      "[[0.67692992 0.32286184 0.         0.        ]\n",
      " [0.34184046 0.         0.65796553 0.        ]\n",
      " [0.51745555 0.14818501 0.33426577 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.3384888  0.         0.66132197]\n",
      " [0.06770208 0.62751111 0.         0.30469268]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.67103798 0.         0.         0.32876009]\n",
      " [0.68463606 0.         0.3151666  0.        ]\n",
      " [0.64850245 0.         0.24513567 0.10626154]\n",
      " [0.         0.         0.89039949 0.10938683]]\n",
      "ok\n",
      "[[0.67692992 0.32286184 0.         0.        ]\n",
      " [0.34184046 0.         0.65796553 0.        ]\n",
      " [0.51745555 0.14818501 0.33426577 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.3384888  0.         0.66132197]\n",
      " [0.06770208 0.62751111 0.         0.30469268]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.67103798 0.         0.         0.32876009]\n",
      " [0.68463606 0.         0.3151666  0.        ]\n",
      " [0.64850245 0.         0.24513567 0.10626154]\n",
      " [0.         0.         0.89039949 0.10938683]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.005658\n",
      "         Iterations: 51\n",
      "         Function evaluations: 154\n",
      "         Gradient evaluations: 145\n",
      "[[0.68060303 0.31918186 0.         0.        ]\n",
      " [0.32720042 0.         0.67260561 0.        ]\n",
      " [0.53461306 0.14199869 0.32329437 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.33332604 0.         0.6664893 ]\n",
      " [0.05952543 0.65420712 0.         0.28617248]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.68862662 0.         0.         0.31117362]\n",
      " [0.69424562 0.         0.30555673 0.        ]\n",
      " [0.66469938 0.         0.23898711 0.09621374]\n",
      " [0.         0.         0.90510149 0.09468911]]\n",
      "ok\n",
      "[[0.68060303 0.31918186 0.         0.        ]\n",
      " [0.32720042 0.         0.67260561 0.        ]\n",
      " [0.53461306 0.14199869 0.32329437 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.33332604 0.         0.6664893 ]\n",
      " [0.05952543 0.65420712 0.         0.28617248]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.68862662 0.         0.         0.31117362]\n",
      " [0.69424562 0.         0.30555673 0.        ]\n",
      " [0.66469938 0.         0.23898711 0.09621374]\n",
      " [0.         0.         0.90510149 0.09468911]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.003295\n",
      "         Iterations: 56\n",
      "         Function evaluations: 189\n",
      "         Gradient evaluations: 178\n",
      "[[0.6805232  0.31926191 0.         0.        ]\n",
      " [0.3103819  0.         0.68942619 0.        ]\n",
      " [0.54958418 0.13764795 0.31267425 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.33119509 0.         0.66861947]\n",
      " [0.05327204 0.67531803 0.         0.27131469]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.70670141 0.         0.         0.2930982 ]\n",
      " [0.70288523 0.         0.29691638 0.        ]\n",
      " [0.67822883 0.         0.2338832  0.08778806]\n",
      " [0.         0.         0.91728667 0.08250607]]\n",
      "ok\n",
      "[[0.6805232  0.31926191 0.         0.        ]\n",
      " [0.3103819  0.         0.68942619 0.        ]\n",
      " [0.54958418 0.13764795 0.31267425 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.33119509 0.         0.66861947]\n",
      " [0.05327204 0.67531803 0.         0.27131469]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.70670141 0.         0.         0.2930982 ]\n",
      " [0.70288523 0.         0.29691638 0.        ]\n",
      " [0.67822883 0.         0.2338832  0.08778806]\n",
      " [0.         0.         0.91728667 0.08250607]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -0.004082\n",
      "         Iterations: 53\n",
      "         Function evaluations: 104\n",
      "         Gradient evaluations: 104\n",
      "[[0.69456743 0.30521681 0.         0.        ]\n",
      " [0.29317317 0.         0.70663208 0.        ]\n",
      " [0.5622302  0.12691021 0.3107642  0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.31128134 0.         0.68853494]\n",
      " [0.04769354 0.68365198 0.         0.26855928]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.71301719 0.         0.         0.28678457]\n",
      " [0.71027    0.         0.28953223 0.        ]\n",
      " [0.69075804 0.         0.2268078  0.08233521]\n",
      " [0.         0.         0.92742887 0.07236267]]\n",
      "ok\n",
      "[[0.69456743 0.30521681 0.         0.        ]\n",
      " [0.29317317 0.         0.70663208 0.        ]\n",
      " [0.5622302  0.12691021 0.3107642  0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.31128134 0.         0.68853494]\n",
      " [0.04769354 0.68365198 0.         0.26855928]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.71301719 0.         0.         0.28678457]\n",
      " [0.71027    0.         0.28953223 0.        ]\n",
      " [0.69075804 0.         0.2268078  0.08233521]\n",
      " [0.         0.         0.92742887 0.07236267]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.001733\n",
      "         Iterations: 52\n",
      "         Function evaluations: 152\n",
      "         Gradient evaluations: 142\n",
      "[[0.69568705 0.30409765 0.         0.        ]\n",
      " [0.27703497 0.         0.72277342 0.        ]\n",
      " [0.57692087 0.12173133 0.30125415 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.30712162 0.         0.69269424]\n",
      " [0.04189043 0.70709472 0.         0.25092011]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.72975297 0.         0.         0.27004731]\n",
      " [0.71929061 0.         0.28051184 0.        ]\n",
      " [0.70488115 0.         0.22014289 0.07487658]\n",
      " [0.         0.         0.93813542 0.0616563 ]]\n",
      "ok\n",
      "[[0.69568705 0.30409765 0.         0.        ]\n",
      " [0.27703497 0.         0.72277342 0.        ]\n",
      " [0.57692087 0.12173133 0.30125415 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.30712162 0.         0.69269424]\n",
      " [0.04189043 0.70709472 0.         0.25092011]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.72975297 0.         0.         0.27004731]\n",
      " [0.71929061 0.         0.28051184 0.        ]\n",
      " [0.70488115 0.         0.22014289 0.07487658]\n",
      " [0.         0.         0.93813542 0.0616563 ]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000009\n",
      "         Iterations: 43\n",
      "         Function evaluations: 87\n",
      "         Gradient evaluations: 87\n",
      "[[0.69213831 0.3076469  0.         0.        ]\n",
      " [0.26151567 0.         0.73829403 0.        ]\n",
      " [0.59577713 0.12014883 0.28398118 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.31179312 0.         0.68802097]\n",
      " [0.03689307 0.73716009 0.         0.22585406]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.75203777 0.         0.         0.24776233]\n",
      " [0.72922999 0.         0.2705721  0.        ]\n",
      " [0.71908733 0.         0.21435084 0.06646199]\n",
      " [0.         0.         0.9477228  0.05206989]]\n",
      "ok\n",
      "[[0.69213831 0.3076469  0.         0.        ]\n",
      " [0.26151567 0.         0.73829403 0.        ]\n",
      " [0.59577713 0.12014883 0.28398118 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.31179312 0.         0.68802097]\n",
      " [0.03689307 0.73716009 0.         0.22585406]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.75203777 0.         0.         0.24776233]\n",
      " [0.72922999 0.         0.2705721  0.        ]\n",
      " [0.71908733 0.         0.21435084 0.06646199]\n",
      " [0.         0.         0.9477228  0.05206989]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.003289\n",
      "         Iterations: 48\n",
      "         Function evaluations: 93\n",
      "         Gradient evaluations: 93\n",
      "[[0.70261425 0.29717439 0.         0.        ]\n",
      " [0.25021489 0.         0.74958916 0.        ]\n",
      " [0.60900057 0.11117046 0.27973417 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.29678576 0.         0.70302761]\n",
      " [0.032152   0.74451178 0.         0.22324058]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.75711479 0.         0.         0.24268695]\n",
      " [0.73522682 0.         0.26457544 0.        ]\n",
      " [0.7287496  0.         0.20833445 0.06281703]\n",
      " [0.         0.         0.95396054 0.04583273]]\n",
      "ok\n",
      "[[0.70261425 0.29717439 0.         0.        ]\n",
      " [0.25021489 0.         0.74958916 0.        ]\n",
      " [0.60900057 0.11117046 0.27973417 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.29678576 0.         0.70302761]\n",
      " [0.032152   0.74451178 0.         0.22324058]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.75711479 0.         0.         0.24268695]\n",
      " [0.73522682 0.         0.26457544 0.        ]\n",
      " [0.7287496  0.         0.20833445 0.06281703]\n",
      " [0.         0.         0.95396054 0.04583273]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.003422\n",
      "         Iterations: 49\n",
      "         Function evaluations: 152\n",
      "         Gradient evaluations: 141\n",
      "[[0.71234827 0.28743908 0.         0.        ]\n",
      " [0.23735243 0.         0.76245367 0.        ]\n",
      " [0.62351795 0.10269318 0.2736946  0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.28265333 0.         0.71716064]\n",
      " [0.02844632 0.74892852 0.         0.22252797]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.76013034 0.         0.         0.23967083]\n",
      " [0.73908398 0.         0.26071745 0.        ]\n",
      " [0.73446001 0.         0.2049028  0.06053784]\n",
      " [0.         0.         0.95888466 0.04091112]]\n",
      "ok\n",
      "[[0.71234827 0.28743908 0.         0.        ]\n",
      " [0.23735243 0.         0.76245367 0.        ]\n",
      " [0.62351795 0.10269318 0.2736946  0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.28265333 0.         0.71716064]\n",
      " [0.02844632 0.74892852 0.         0.22252797]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.76013034 0.         0.         0.23967083]\n",
      " [0.73908398 0.         0.26071745 0.        ]\n",
      " [0.73446001 0.         0.2049028  0.06053784]\n",
      " [0.         0.         0.95888466 0.04091112]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.007884\n",
      "         Iterations: 51\n",
      "         Function evaluations: 157\n",
      "         Gradient evaluations: 145\n",
      "[[0.7146619  0.2851288  0.         0.        ]\n",
      " [0.22879828 0.         0.77100768 0.        ]\n",
      " [0.63779529 0.09758532 0.26452553 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.27996801 0.         0.7198423 ]\n",
      " [0.02569344 0.76224729 0.         0.21196394]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.76913205 0.         0.         0.23066914]\n",
      " [0.74498546 0.         0.25481608 0.        ]\n",
      " [0.7432012  0.         0.20028151 0.05641807]\n",
      " [0.         0.         0.96410913 0.03568567]]\n",
      "ok\n",
      "[[0.7146619  0.2851288  0.         0.        ]\n",
      " [0.22879828 0.         0.77100768 0.        ]\n",
      " [0.63779529 0.09758532 0.26452553 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.27996801 0.         0.7198423 ]\n",
      " [0.02569344 0.76224729 0.         0.21196394]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.76913205 0.         0.         0.23066914]\n",
      " [0.74498546 0.         0.25481608 0.        ]\n",
      " [0.7432012  0.         0.20028151 0.05641807]\n",
      " [0.         0.         0.96410913 0.03568567]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.006315\n",
      "         Iterations: 52\n",
      "         Function evaluations: 102\n",
      "         Gradient evaluations: 102\n",
      "[[0.72913284 0.270653   0.         0.        ]\n",
      " [0.21711154 0.         0.78269463 0.        ]\n",
      " [0.65041034 0.08784048 0.26165437 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.25919018 0.         0.7406259 ]\n",
      " [0.02519606 0.75697708 0.         0.21772918]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.76786491 0.         0.         0.23193652]\n",
      " [0.7474061  0.         0.25239513 0.        ]\n",
      " [0.7473136  0.         0.19715561 0.05543157]\n",
      " [0.         0.         0.96774002 0.0320564 ]]\n",
      "ok\n",
      "[[0.72913284 0.270653   0.         0.        ]\n",
      " [0.21711154 0.         0.78269463 0.        ]\n",
      " [0.65041034 0.08784048 0.26165437 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.25919018 0.         0.7406259 ]\n",
      " [0.02519606 0.75697708 0.         0.21772918]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.76786491 0.         0.         0.23193652]\n",
      " [0.7474061  0.         0.25239513 0.        ]\n",
      " [0.7473136  0.         0.19715561 0.05543157]\n",
      " [0.         0.         0.96774002 0.0320564 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.005892\n",
      "         Iterations: 60\n",
      "         Function evaluations: 181\n",
      "         Gradient evaluations: 171\n",
      "[[0.72481545 0.27497533 0.         0.        ]\n",
      " [0.20930215 0.         0.79050579 0.        ]\n",
      " [0.6682258  0.08576428 0.245917   0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.26556149 0.         0.73424698]\n",
      " [0.02225346 0.7763123  0.         0.20133931]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.78200375 0.         0.         0.21779666]\n",
      " [0.75394724 0.         0.24585428 0.        ]\n",
      " [0.75543664 0.         0.19348589 0.05097784]\n",
      " [0.         0.         0.97224667 0.02754908]]\n",
      "ok\n",
      "[[0.72481545 0.27497533 0.         0.        ]\n",
      " [0.20930215 0.         0.79050579 0.        ]\n",
      " [0.6682258  0.08576428 0.245917   0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.26556149 0.         0.73424698]\n",
      " [0.02225346 0.7763123  0.         0.20133931]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.78200375 0.         0.         0.21779666]\n",
      " [0.75394724 0.         0.24585428 0.        ]\n",
      " [0.75543664 0.         0.19348589 0.05097784]\n",
      " [0.         0.         0.97224667 0.02754908]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.002963\n",
      "         Iterations: 50\n",
      "         Function evaluations: 183\n",
      "         Gradient evaluations: 172\n",
      "[[0.72745955 0.27232869 0.         0.        ]\n",
      " [0.19926032 0.         0.80054775 0.        ]\n",
      " [0.68359963 0.08192787 0.23437885 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.26064586 0.         0.73916605]\n",
      " [0.01973964 0.78723662 0.         0.1929275 ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.79024981 0.         0.         0.20955077]\n",
      " [0.75846164 0.         0.24133982 0.        ]\n",
      " [0.76115378 0.         0.19047734 0.04826927]\n",
      " [0.         0.         0.97527021 0.02452653]]\n",
      "ok\n",
      "[[0.72745955 0.27232869 0.         0.        ]\n",
      " [0.19926032 0.         0.80054775 0.        ]\n",
      " [0.68359963 0.08192787 0.23437885 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.26064586 0.         0.73916605]\n",
      " [0.01973964 0.78723662 0.         0.1929275 ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.79024981 0.         0.         0.20955077]\n",
      " [0.75846164 0.         0.24133982 0.        ]\n",
      " [0.76115378 0.         0.19047734 0.04826927]\n",
      " [0.         0.         0.97527021 0.02452653]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.003093\n",
      "         Iterations: 58\n",
      "         Function evaluations: 112\n",
      "         Gradient evaluations: 112\n",
      "[[0.71199119 0.28780007 0.         0.        ]\n",
      " [0.19115936 0.         0.80865142 0.        ]\n",
      " [0.70440079 0.08268888 0.21281954 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.28401471 0.         0.71579053]\n",
      " [0.01860779 0.81747369 0.         0.16382472]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.81083169 0.         0.         0.18896873]\n",
      " [0.76714975 0.         0.23265212 0.        ]\n",
      " [0.77113606 0.         0.18632114 0.04244288]\n",
      " [0.         0.         0.97920297 0.02059264]]\n",
      "ok\n",
      "[[0.71199119 0.28780007 0.         0.        ]\n",
      " [0.19115936 0.         0.80865142 0.        ]\n",
      " [0.70440079 0.08268888 0.21281954 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.28401471 0.         0.71579053]\n",
      " [0.01860779 0.81747369 0.         0.16382472]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.81083169 0.         0.         0.18896873]\n",
      " [0.76714975 0.         0.23265212 0.        ]\n",
      " [0.77113606 0.         0.18632114 0.04244288]\n",
      " [0.         0.         0.97920297 0.02059264]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.006911\n",
      "         Iterations: 45\n",
      "         Function evaluations: 90\n",
      "         Gradient evaluations: 90\n",
      "[[0.70086982 0.29892145 0.         0.        ]\n",
      " [0.18315206 0.         0.81665722 0.        ]\n",
      " [0.72183598 0.08073531 0.19733673 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.29766848 0.         0.70213846]\n",
      " [0.01673431 0.83760255 0.         0.14556722]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.82520041 0.         0.         0.17459971]\n",
      " [0.77238556 0.         0.22741528 0.        ]\n",
      " [0.77632888 0.         0.18448767 0.03908331]\n",
      " [0.         0.         0.98139425 0.01840401]]\n",
      "ok\n",
      "[[0.70086982 0.29892145 0.         0.        ]\n",
      " [0.18315206 0.         0.81665722 0.        ]\n",
      " [0.72183598 0.08073531 0.19733673 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.29766848 0.         0.70213846]\n",
      " [0.01673431 0.83760255 0.         0.14556722]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.82520041 0.         0.         0.17459971]\n",
      " [0.77238556 0.         0.22741528 0.        ]\n",
      " [0.77632888 0.         0.18448767 0.03908331]\n",
      " [0.         0.         0.98139425 0.01840401]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.001301\n",
      "         Iterations: 52\n",
      "         Function evaluations: 182\n",
      "         Gradient evaluations: 172\n",
      "[[0.69562374 0.30416732 0.         0.        ]\n",
      " [0.17474906 0.         0.82505982 0.        ]\n",
      " [0.73813502 0.07767949 0.1840937  0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.3030649  0.         0.69674338]\n",
      " [0.01541266 0.84971471 0.         0.13477619]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.83618428 0.         0.         0.163616  ]\n",
      " [0.77619926 0.         0.22360155 0.        ]\n",
      " [0.78039691 0.         0.18266782 0.03683532]\n",
      " [0.         0.         0.98360166 0.01619664]]\n",
      "ok\n",
      "[[0.69562374 0.30416732 0.         0.        ]\n",
      " [0.17474906 0.         0.82505982 0.        ]\n",
      " [0.73813502 0.07767949 0.1840937  0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.3030649  0.         0.69674338]\n",
      " [0.01541266 0.84971471 0.         0.13477619]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.83618428 0.         0.         0.163616  ]\n",
      " [0.77619926 0.         0.22360155 0.        ]\n",
      " [0.78039691 0.         0.18266782 0.03683532]\n",
      " [0.         0.         0.98360166 0.01619664]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.006416\n",
      "         Iterations: 59\n",
      "         Function evaluations: 199\n",
      "         Gradient evaluations: 187\n",
      "[[0.70172512 0.29806558 0.         0.        ]\n",
      " [0.16809977 0.         0.83170603 0.        ]\n",
      " [0.74984165 0.07203474 0.17803009 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.29283971 0.         0.70696976]\n",
      " [0.01384982 0.85142889 0.         0.13462284]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.83752673 0.         0.         0.16227398]\n",
      " [0.77787904 0.         0.22192159 0.        ]\n",
      " [0.78254165 0.         0.18118935 0.03616937]\n",
      " [0.         0.         0.98499547 0.01480288]]\n",
      "ok\n",
      "[[0.70172512 0.29806558 0.         0.        ]\n",
      " [0.16809977 0.         0.83170603 0.        ]\n",
      " [0.74984165 0.07203474 0.17803009 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.29283971 0.         0.70696976]\n",
      " [0.01384982 0.85142889 0.         0.13462284]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.83752673 0.         0.         0.16227398]\n",
      " [0.77787904 0.         0.22192159 0.        ]\n",
      " [0.78254165 0.         0.18118935 0.03616937]\n",
      " [0.         0.         0.98499547 0.01480288]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.006262\n",
      "         Iterations: 47\n",
      "         Function evaluations: 94\n",
      "         Gradient evaluations: 94\n",
      "[[0.70759151 0.29219597 0.         0.        ]\n",
      " [0.15883248 0.         0.8409756  0.        ]\n",
      " [0.76261458 0.06680001 0.17049195 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.27891564 0.         0.72089601]\n",
      " [0.01244642 0.85307176 0.         0.1343835 ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.83914834 0.         0.         0.16065232]\n",
      " [0.77951993 0.         0.22028068 0.        ]\n",
      " [0.78450852 0.         0.17987647 0.03551529]\n",
      " [0.         0.         0.98635192 0.01344665]]\n",
      "ok\n",
      "[[0.70759151 0.29219597 0.         0.        ]\n",
      " [0.15883248 0.         0.8409756  0.        ]\n",
      " [0.76261458 0.06680001 0.17049195 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.27891564 0.         0.72089601]\n",
      " [0.01244642 0.85307176 0.         0.1343835 ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.83914834 0.         0.         0.16065232]\n",
      " [0.77951993 0.         0.22028068 0.        ]\n",
      " [0.78450852 0.         0.17987647 0.03551529]\n",
      " [0.         0.         0.98635192 0.01344665]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.010720\n",
      "         Iterations: 58\n",
      "         Function evaluations: 116\n",
      "         Gradient evaluations: 116\n",
      "[[0.71111765 0.2886753  0.         0.        ]\n",
      " [0.15422962 0.         0.84557509 0.        ]\n",
      " [0.7742887  0.06214781 0.16347032 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.27212512 0.         0.72768228]\n",
      " [0.01245255 0.85351567 0.         0.13393253]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.84007795 0.         0.         0.15972224]\n",
      " [0.77998465 0.         0.21981551 0.        ]\n",
      " [0.78491062 0.         0.17964372 0.0353457 ]\n",
      " [0.         0.         0.98738906 0.01241056]]\n",
      "ok\n",
      "[[0.71111765 0.2886753  0.         0.        ]\n",
      " [0.15422962 0.         0.84557509 0.        ]\n",
      " [0.7742887  0.06214781 0.16347032 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.27212512 0.         0.72768228]\n",
      " [0.01245255 0.85351567 0.         0.13393253]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.84007795 0.         0.         0.15972224]\n",
      " [0.77998465 0.         0.21981551 0.        ]\n",
      " [0.78491062 0.         0.17964372 0.0353457 ]\n",
      " [0.         0.         0.98738906 0.01241056]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.006360\n",
      "         Iterations: 53\n",
      "         Function evaluations: 107\n",
      "         Gradient evaluations: 107\n",
      "[[0.72240944 0.27737838 0.         0.        ]\n",
      " [0.14646176 0.         0.85334417 0.        ]\n",
      " [0.78349491 0.05663162 0.15977981 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.25546556 0.         0.74434683]\n",
      " [0.0125126  0.84883416 0.         0.13855356]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.83787149 0.         0.         0.16192893]\n",
      " [0.77997048 0.         0.21982974 0.        ]\n",
      " [0.78505865 0.         0.17925424 0.03558732]\n",
      " [0.         0.         0.98826608 0.01153332]]\n",
      "ok\n",
      "[[0.72240944 0.27737838 0.         0.        ]\n",
      " [0.14646176 0.         0.85334417 0.        ]\n",
      " [0.78349491 0.05663162 0.15977981 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.25546556 0.         0.74434683]\n",
      " [0.0125126  0.84883416 0.         0.13855356]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.83787149 0.         0.         0.16192893]\n",
      " [0.77997048 0.         0.21982974 0.        ]\n",
      " [0.78505865 0.         0.17925424 0.03558732]\n",
      " [0.         0.         0.98826608 0.01153332]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.009670\n",
      "         Iterations: 51\n",
      "         Function evaluations: 173\n",
      "         Gradient evaluations: 162\n",
      "[[0.72901937 0.27077031 0.         0.        ]\n",
      " [0.13947595 0.         0.86032958 0.        ]\n",
      " [0.7942173  0.05219863 0.15349067 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.24313366 0.         0.75667812]\n",
      " [0.01128866 0.84823823 0.         0.14037411]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.8377952  0.         0.         0.16200536]\n",
      " [0.78092615 0.         0.21887435 0.        ]\n",
      " [0.78633732 0.         0.1782179  0.03534507]\n",
      " [0.         0.         0.98915732 0.01064152]]\n",
      "ok\n",
      "[[0.72901937 0.27077031 0.         0.        ]\n",
      " [0.13947595 0.         0.86032958 0.        ]\n",
      " [0.7942173  0.05219863 0.15349067 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.24313366 0.         0.75667812]\n",
      " [0.01128866 0.84823823 0.         0.14037411]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.8377952  0.         0.         0.16200536]\n",
      " [0.78092615 0.         0.21887435 0.        ]\n",
      " [0.78633732 0.         0.1782179  0.03534507]\n",
      " [0.         0.         0.98915732 0.01064152]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.003384\n",
      "         Iterations: 52\n",
      "         Function evaluations: 151\n",
      "         Gradient evaluations: 140\n",
      "[[0.73925569 0.26053691 0.         0.        ]\n",
      " [0.13488008 0.         0.86492329 0.        ]\n",
      " [0.80305075 0.04702643 0.14982869 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.22836991 0.         0.77143999]\n",
      " [0.01144013 0.84073176 0.         0.14772766]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.83384356 0.         0.         0.16595688]\n",
      " [0.78046203 0.         0.21933817 0.        ]\n",
      " [0.78614292 0.         0.17783509 0.03592229]\n",
      " [0.         0.         0.98982441 0.00997494]]\n",
      "ok\n",
      "[[0.73925569 0.26053691 0.         0.        ]\n",
      " [0.13488008 0.         0.86492329 0.        ]\n",
      " [0.80305075 0.04702643 0.14982869 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.22836991 0.         0.77143999]\n",
      " [0.01144013 0.84073176 0.         0.14772766]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.83384356 0.         0.         0.16595688]\n",
      " [0.78046203 0.         0.21933817 0.        ]\n",
      " [0.78614292 0.         0.17783509 0.03592229]\n",
      " [0.         0.         0.98982441 0.00997494]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.009267\n",
      "         Iterations: 54\n",
      "         Function evaluations: 110\n",
      "         Gradient evaluations: 110\n",
      "[[0.74914113 0.2506476  0.         0.        ]\n",
      " [0.12839917 0.         0.8714068  0.        ]\n",
      " [0.81277646 0.04238191 0.14474772 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.21187188 0.         0.78794204]\n",
      " [0.01156685 0.83359991 0.         0.154733  ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.83071144 0.         0.         0.16908896]\n",
      " [0.7801128  0.         0.21968736 0.        ]\n",
      " [0.78592735 0.         0.17756554 0.03640733]\n",
      " [0.         0.         0.99061942 0.00918007]]\n",
      "ok\n",
      "[[0.74914113 0.2506476  0.         0.        ]\n",
      " [0.12839917 0.         0.8714068  0.        ]\n",
      " [0.81277646 0.04238191 0.14474772 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.21187188 0.         0.78794204]\n",
      " [0.01156685 0.83359991 0.         0.154733  ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.83071144 0.         0.         0.16908896]\n",
      " [0.7801128  0.         0.21968736 0.        ]\n",
      " [0.78592735 0.         0.17756554 0.03640733]\n",
      " [0.         0.         0.99061942 0.00918007]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.005973\n",
      "         Iterations: 45\n",
      "         Function evaluations: 131\n",
      "         Gradient evaluations: 122\n",
      "[[0.75878399 0.2410077  0.         0.        ]\n",
      " [0.12321281 0.         0.87659102 0.        ]\n",
      " [0.82204035 0.03831432 0.13955136 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.19319605 0.         0.80661605]\n",
      " [0.01053197 0.82512714 0.         0.16424011]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.82647823 0.         0.         0.17332221]\n",
      " [0.77952601 0.         0.22027418 0.        ]\n",
      " [0.78562026 0.         0.17720698 0.03707307]\n",
      " [0.         0.         0.99131086 0.0084885 ]]\n",
      "ok\n",
      "[[0.75878399 0.2410077  0.         0.        ]\n",
      " [0.12321281 0.         0.87659102 0.        ]\n",
      " [0.82204035 0.03831432 0.13955136 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.19319605 0.         0.80661605]\n",
      " [0.01053197 0.82512714 0.         0.16424011]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.82647823 0.         0.         0.17332221]\n",
      " [0.77952601 0.         0.22027418 0.        ]\n",
      " [0.78562026 0.         0.17720698 0.03707307]\n",
      " [0.         0.         0.99131086 0.0084885 ]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.007609\n",
      "         Iterations: 56\n",
      "         Function evaluations: 110\n",
      "         Gradient evaluations: 110\n",
      "[[0.75709179 0.24270406 0.         0.        ]\n",
      " [0.12067193 0.         0.87913225 0.        ]\n",
      " [0.83342192 0.03633045 0.13015517 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.19455169 0.         0.80525199]\n",
      " [0.01040981 0.8297577  0.         0.15973458]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.83092527 0.         0.         0.16887503]\n",
      " [0.78125682 0.         0.21854367 0.        ]\n",
      " [0.78739739 0.         0.17633365 0.03616906]\n",
      " [0.         0.         0.99212881 0.00767028]]\n",
      "ok\n",
      "[[0.75709179 0.24270406 0.         0.        ]\n",
      " [0.12067193 0.         0.87913225 0.        ]\n",
      " [0.83342192 0.03633045 0.13015517 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.19455169 0.         0.80525199]\n",
      " [0.01040981 0.8297577  0.         0.15973458]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.83092527 0.         0.         0.16887503]\n",
      " [0.78125682 0.         0.21854367 0.        ]\n",
      " [0.78739739 0.         0.17633365 0.03616906]\n",
      " [0.         0.         0.99212881 0.00767028]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.010136\n",
      "         Iterations: 53\n",
      "         Function evaluations: 172\n",
      "         Gradient evaluations: 161\n",
      "[[0.75137593 0.24841686 0.         0.        ]\n",
      " [0.11694889 0.         0.88285855 0.        ]\n",
      " [0.84524901 0.03523819 0.11942119 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.19993788 0.         0.79986722]\n",
      " [0.01017231 0.84171554 0.         0.14801537]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.83962144 0.         0.         0.1601788 ]\n",
      " [0.78429072 0.         0.21550989 0.        ]\n",
      " [0.79025711 0.         0.17521174 0.03443108]\n",
      " [0.         0.         0.99303172 0.00676735]]\n",
      "ok\n",
      "[[0.75137593 0.24841686 0.         0.        ]\n",
      " [0.11694889 0.         0.88285855 0.        ]\n",
      " [0.84524901 0.03523819 0.11942119 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.19993788 0.         0.79986722]\n",
      " [0.01017231 0.84171554 0.         0.14801537]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.83962144 0.         0.         0.1601788 ]\n",
      " [0.78429072 0.         0.21550989 0.        ]\n",
      " [0.79025711 0.         0.17521174 0.03443108]\n",
      " [0.         0.         0.99303172 0.00676735]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.007598\n",
      "         Iterations: 53\n",
      "         Function evaluations: 161\n",
      "         Gradient evaluations: 151\n",
      "[[0.73935533 0.260438   0.         0.        ]\n",
      " [0.11353587 0.         0.88627327 0.        ]\n",
      " [0.85756068 0.03417248 0.1081769  0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.21390937 0.         0.78589304]\n",
      " [0.00911926 0.85970016 0.         0.13108539]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.85155268 0.         0.         0.14824771]\n",
      " [0.78781688 0.         0.21198369 0.        ]\n",
      " [0.79347964 0.         0.17438489 0.03203514]\n",
      " [0.         0.         0.99389831 0.00590126]]\n",
      "ok\n",
      "[[0.73935533 0.260438   0.         0.        ]\n",
      " [0.11353587 0.         0.88627327 0.        ]\n",
      " [0.85756068 0.03417248 0.1081769  0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.21390937 0.         0.78589304]\n",
      " [0.00911926 0.85970016 0.         0.13108539]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.85155268 0.         0.         0.14824771]\n",
      " [0.78781688 0.         0.21198369 0.        ]\n",
      " [0.79347964 0.         0.17438489 0.03203514]\n",
      " [0.         0.         0.99389831 0.00590126]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.008110\n",
      "         Iterations: 52\n",
      "         Function evaluations: 174\n",
      "         Gradient evaluations: 165\n",
      "[[0.73925756 0.26053574 0.         0.        ]\n",
      " [0.11011312 0.         0.88969235 0.        ]\n",
      " [0.86577823 0.03185969 0.10227014 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.21072306 0.         0.78908353]\n",
      " [0.00913604 0.86218827 0.         0.1285766 ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.85366812 0.         0.         0.14613197]\n",
      " [0.78831411 0.         0.21148595 0.        ]\n",
      " [0.79370461 0.         0.17444804 0.03174724]\n",
      " [0.         0.         0.99426872 0.00553137]]\n",
      "ok\n",
      "[[0.73925756 0.26053574 0.         0.        ]\n",
      " [0.11011312 0.         0.88969235 0.        ]\n",
      " [0.86577823 0.03185969 0.10227014 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.21072306 0.         0.78908353]\n",
      " [0.00913604 0.86218827 0.         0.1285766 ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.85366812 0.         0.         0.14613197]\n",
      " [0.78831411 0.         0.21148595 0.        ]\n",
      " [0.79370461 0.         0.17444804 0.03174724]\n",
      " [0.         0.         0.99426872 0.00553137]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.005417\n",
      "         Iterations: 61\n",
      "         Function evaluations: 194\n",
      "         Gradient evaluations: 183\n",
      "[[0.75528615 0.2445044  0.         0.        ]\n",
      " [0.10495735 0.         0.894846   0.        ]\n",
      " [0.8693552  0.03015271 0.10039775 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.18933677 0.         0.81047768]\n",
      " [0.00948942 0.85089208 0.         0.13951576]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.84504727 0.         0.         0.15475288]\n",
      " [0.7859914  0.         0.2138084  0.        ]\n",
      " [0.79163001 0.         0.17489435 0.03337597]\n",
      " [0.         0.         0.99447351 0.00532649]]\n",
      "ok\n",
      "[[0.75528615 0.2445044  0.         0.        ]\n",
      " [0.10495735 0.         0.894846   0.        ]\n",
      " [0.8693552  0.03015271 0.10039775 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.18933677 0.         0.81047768]\n",
      " [0.00948942 0.85089208 0.         0.13951576]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.84504727 0.         0.         0.15475288]\n",
      " [0.7859914  0.         0.2138084  0.        ]\n",
      " [0.79163001 0.         0.17489435 0.03337597]\n",
      " [0.         0.         0.99447351 0.00532649]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.009117\n",
      "         Iterations: 53\n",
      "         Function evaluations: 104\n",
      "         Gradient evaluations: 104\n",
      "[[0.7564448  0.24334521 0.         0.        ]\n",
      " [0.10041836 0.         0.89938928 0.        ]\n",
      " [0.87831642 0.02810632 0.09348552 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.18453445 0.         0.81527531]\n",
      " [0.00858981 0.85541911 0.         0.1358929 ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.84819301 0.         0.         0.15160742]\n",
      " [0.78747945 0.         0.21232094 0.        ]\n",
      " [0.79308659 0.         0.17421392 0.03259951]\n",
      " [0.         0.         0.99490812 0.00489132]]\n",
      "ok\n",
      "[[0.7564448  0.24334521 0.         0.        ]\n",
      " [0.10041836 0.         0.89938928 0.        ]\n",
      " [0.87831642 0.02810632 0.09348552 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.18453445 0.         0.81527531]\n",
      " [0.00858981 0.85541911 0.         0.1358929 ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.84819301 0.         0.         0.15160742]\n",
      " [0.78747945 0.         0.21232094 0.        ]\n",
      " [0.79308659 0.         0.17421392 0.03259951]\n",
      " [0.         0.         0.99490812 0.00489132]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.010230\n",
      "         Iterations: 59\n",
      "         Function evaluations: 194\n",
      "         Gradient evaluations: 182\n",
      "[[0.75481327 0.24498066 0.         0.        ]\n",
      " [0.09761217 0.         0.90219382 0.        ]\n",
      " [0.8854874  0.02653817 0.0878828  0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.18471056 0.         0.81509441]\n",
      " [0.00863282 0.85969364 0.         0.1315742 ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.85158012 0.         0.         0.14821975]\n",
      " [0.78789022 0.         0.21190966 0.        ]\n",
      " [0.79296355 0.         0.17473294 0.03220321]\n",
      " [0.         0.         0.99532761 0.00447294]]\n",
      "ok\n",
      "[[0.75481327 0.24498066 0.         0.        ]\n",
      " [0.09761217 0.         0.90219382 0.        ]\n",
      " [0.8854874  0.02653817 0.0878828  0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.18471056 0.         0.81509441]\n",
      " [0.00863282 0.85969364 0.         0.1315742 ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.85158012 0.         0.         0.14821975]\n",
      " [0.78789022 0.         0.21190966 0.        ]\n",
      " [0.79296355 0.         0.17473294 0.03220321]\n",
      " [0.         0.         0.99532761 0.00447294]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.004859\n",
      "         Iterations: 62\n",
      "         Function evaluations: 243\n",
      "         Gradient evaluations: 234\n",
      "[[0.74472163 0.25507067 0.         0.        ]\n",
      " [0.09386635 0.         0.90594334 0.        ]\n",
      " [0.8917285  0.02651985 0.08166035 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.19551991 0.         0.80428353]\n",
      " [0.00838531 0.87557326 0.         0.11594541]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.86179739 0.         0.         0.13800295]\n",
      " [0.79084795 0.         0.20895236 0.        ]\n",
      " [0.79509939 0.         0.17437607 0.03042412]\n",
      " [0.         0.         0.99583818 0.0039619 ]]\n",
      "ok\n",
      "[[0.74472163 0.25507067 0.         0.        ]\n",
      " [0.09386635 0.         0.90594334 0.        ]\n",
      " [0.8917285  0.02651985 0.08166035 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.19551991 0.         0.80428353]\n",
      " [0.00838531 0.87557326 0.         0.11594541]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.86179739 0.         0.         0.13800295]\n",
      " [0.79084795 0.         0.20895236 0.        ]\n",
      " [0.79509939 0.         0.17437607 0.03042412]\n",
      " [0.         0.         0.99583818 0.0039619 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.008704\n",
      "         Iterations: 49\n",
      "         Function evaluations: 99\n",
      "         Gradient evaluations: 99\n",
      "[[0.74095073 0.25884039 0.         0.        ]\n",
      " [0.09040093 0.         0.90940714 0.        ]\n",
      " [0.90017978 0.02476859 0.07496049 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.1970253  0.         0.80278204]\n",
      " [0.00761161 0.88244271 0.         0.10984804]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.86728132 0.         0.         0.1325191 ]\n",
      " [0.79268451 0.         0.20711579 0.        ]\n",
      " [0.79647471 0.         0.17397353 0.02945159]\n",
      " [0.         0.         0.99606714 0.00373272]]\n",
      "ok\n",
      "[[0.74095073 0.25884039 0.         0.        ]\n",
      " [0.09040093 0.         0.90940714 0.        ]\n",
      " [0.90017978 0.02476859 0.07496049 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.1970253  0.         0.80278204]\n",
      " [0.00761161 0.88244271 0.         0.10984804]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.86728132 0.         0.         0.1325191 ]\n",
      " [0.79268451 0.         0.20711579 0.        ]\n",
      " [0.79647471 0.         0.17397353 0.02945159]\n",
      " [0.         0.         0.99606714 0.00373272]]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.009062\n",
      "         Iterations: 53\n",
      "         Function evaluations: 104\n",
      "         Gradient evaluations: 104\n",
      "[[0.758676   0.24111339 0.         0.        ]\n",
      " [0.08594932 0.         0.91385445 0.        ]\n",
      " [0.9043196  0.02121138 0.07437433 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.16942991 0.         0.83038555]\n",
      " [0.00790365 0.87461854 0.         0.11737532]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.85921958 0.         0.         0.14058047]\n",
      " [0.79078513 0.         0.20901499 0.        ]\n",
      " [0.79521096 0.         0.1737238  0.03096578]\n",
      " [0.         0.         0.99617076 0.00362855]]\n",
      "ok\n",
      "[[0.758676   0.24111339 0.         0.        ]\n",
      " [0.08594932 0.         0.91385445 0.        ]\n",
      " [0.9043196  0.02121138 0.07437433 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.16942991 0.         0.83038555]\n",
      " [0.00790365 0.87461854 0.         0.11737532]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.85921958 0.         0.         0.14058047]\n",
      " [0.79078513 0.         0.20901499 0.        ]\n",
      " [0.79521096 0.         0.1737238  0.03096578]\n",
      " [0.         0.         0.99617076 0.00362855]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.009710\n",
      "         Iterations: 54\n",
      "         Function evaluations: 168\n",
      "         Gradient evaluations: 156\n",
      "[[0.76280885 0.23698447 0.         0.        ]\n",
      " [0.08306952 0.         0.91673519 0.        ]\n",
      " [0.90914655 0.01970666 0.07105432 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.16334565 0.         0.83646282]\n",
      " [0.00797601 0.87359299 0.         0.11833135]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.85911426 0.         0.         0.1406859 ]\n",
      " [0.79088237 0.         0.20891773 0.        ]\n",
      " [0.79522719 0.         0.17366324 0.03100962]\n",
      " [0.         0.         0.99643121 0.00336868]]\n",
      "ok\n",
      "[[0.76280885 0.23698447 0.         0.        ]\n",
      " [0.08306952 0.         0.91673519 0.        ]\n",
      " [0.90914655 0.01970666 0.07105432 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.16334565 0.         0.83646282]\n",
      " [0.00797601 0.87359299 0.         0.11833135]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.85911426 0.         0.         0.1406859 ]\n",
      " [0.79088237 0.         0.20891773 0.        ]\n",
      " [0.79522719 0.         0.17366324 0.03100962]\n",
      " [0.         0.         0.99643121 0.00336868]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.008356\n",
      "         Iterations: 52\n",
      "         Function evaluations: 154\n",
      "         Gradient evaluations: 143\n",
      "[[0.76871661 0.23107678 0.         0.        ]\n",
      " [0.08017545 0.         0.91962863 0.        ]\n",
      " [0.91448143 0.0183687  0.06705713 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.1551492  0.         0.84465965]\n",
      " [0.00813524 0.86927868 0.         0.12248534]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.85701771 0.         0.         0.14278221]\n",
      " [0.78998894 0.         0.20981088 0.        ]\n",
      " [0.79415047 0.         0.17417175 0.03157777]\n",
      " [0.         0.         0.99658867 0.00321168]]\n",
      "ok\n",
      "[[0.76871661 0.23107678 0.         0.        ]\n",
      " [0.08017545 0.         0.91962863 0.        ]\n",
      " [0.91448143 0.0183687  0.06705713 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.1551492  0.         0.84465965]\n",
      " [0.00813524 0.86927868 0.         0.12248534]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.85701771 0.         0.         0.14278221]\n",
      " [0.78998894 0.         0.20981088 0.        ]\n",
      " [0.79415047 0.         0.17417175 0.03157777]\n",
      " [0.         0.         0.99658867 0.00321168]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.010380\n",
      "         Iterations: 52\n",
      "         Function evaluations: 163\n",
      "         Gradient evaluations: 154\n",
      "[[0.77412485 0.22566731 0.         0.        ]\n",
      " [0.07726056 0.         0.92254437 0.        ]\n",
      " [0.9202056  0.01674273 0.06295942 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.14825906 0.         0.85155113]\n",
      " [0.0082215  0.86774456 0.         0.12393411]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.85630924 0.         0.         0.14349094]\n",
      " [0.78998784 0.         0.20981227 0.        ]\n",
      " [0.7941169  0.         0.17408002 0.03170315]\n",
      " [0.         0.         0.99674179 0.00305806]]\n",
      "ok\n",
      "[[0.77412485 0.22566731 0.         0.        ]\n",
      " [0.07726056 0.         0.92254437 0.        ]\n",
      " [0.9202056  0.01674273 0.06295942 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.14825906 0.         0.85155113]\n",
      " [0.0082215  0.86774456 0.         0.12393411]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.85630924 0.         0.         0.14349094]\n",
      " [0.78998784 0.         0.20981227 0.        ]\n",
      " [0.7941169  0.         0.17408002 0.03170315]\n",
      " [0.         0.         0.99674179 0.00305806]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.009280\n",
      "         Iterations: 48\n",
      "         Function evaluations: 172\n",
      "         Gradient evaluations: 160\n",
      "[[0.77717817 0.22261234 0.         0.        ]\n",
      " [0.07382427 0.         0.92598316 0.        ]\n",
      " [0.92572678 0.01544535 0.05873616 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.14261204 0.         0.85719862]\n",
      " [0.00832489 0.86709996 0.         0.12447512]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.85649619 0.         0.         0.14330362]\n",
      " [0.7894367  0.         0.21036296 0.        ]\n",
      " [0.79297157 0.         0.17499577 0.0319324 ]\n",
      " [0.         0.         0.99686615 0.00293476]]\n",
      "ok\n",
      "[[0.77717817 0.22261234 0.         0.        ]\n",
      " [0.07382427 0.         0.92598316 0.        ]\n",
      " [0.92572678 0.01544535 0.05873616 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.14261204 0.         0.85719862]\n",
      " [0.00832489 0.86709996 0.         0.12447512]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.85649619 0.         0.         0.14330362]\n",
      " [0.7894367  0.         0.21036296 0.        ]\n",
      " [0.79297157 0.         0.17499577 0.0319324 ]\n",
      " [0.         0.         0.99686615 0.00293476]]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.012705\n",
      "         Iterations: 53\n",
      "         Function evaluations: 189\n",
      "         Gradient evaluations: 177\n",
      "[[0.78349775 0.21629524 0.         0.        ]\n",
      " [0.07108733 0.         0.92871702 0.        ]\n",
      " [0.92907998 0.01404294 0.05678447 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.13632397 0.         0.86348637]\n",
      " [0.00758653 0.86481975 0.         0.12749363]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.85411962 0.         0.         0.14568068]\n",
      " [0.78923659 0.         0.2105636  0.        ]\n",
      " [0.79297924 0.         0.1746714  0.03224958]\n",
      " [0.         0.         0.99704171 0.00275785]]\n",
      "ok\n",
      "[[0.78349775 0.21629524 0.         0.        ]\n",
      " [0.07108733 0.         0.92871702 0.        ]\n",
      " [0.92907998 0.01404294 0.05678447 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.13632397 0.         0.86348637]\n",
      " [0.00758653 0.86481975 0.         0.12749363]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.85411962 0.         0.         0.14568068]\n",
      " [0.78923659 0.         0.2105636  0.        ]\n",
      " [0.79297924 0.         0.1746714  0.03224958]\n",
      " [0.         0.         0.99704171 0.00275785]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.009232\n",
      "         Iterations: 56\n",
      "         Function evaluations: 234\n",
      "         Gradient evaluations: 222\n",
      "[[0.77729434 0.22249875 0.         0.        ]\n",
      " [0.06904496 0.         0.93076277 0.        ]\n",
      " [0.93396843 0.013576   0.05236518 0.        ]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.         0.14107135 0.         0.85873209]\n",
      " [0.00745581 0.87590905 0.         0.11653814]\n",
      " [0.99970003 0.         0.         0.        ]\n",
      " [0.86228162 0.         0.         0.1375187 ]\n",
      " [0.79175214 0.         0.20804842 0.        ]\n",
      " [0.79515412 0.         0.17388319 0.03086255]\n",
      " [0.         0.         0.99730671 0.00249289]]\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "policy,theta,phi = REPS_mirror_descent(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_policy(env,policy.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77729434, 0.22249875, 0.        , 0.        ],\n",
       "       [0.06904496, 0.        , 0.93076277, 0.        ],\n",
       "       [0.93396843, 0.013576  , 0.05236518, 0.        ],\n",
       "       [0.99970003, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.14107135, 0.        , 0.85873209],\n",
       "       [0.00745581, 0.87590905, 0.        , 0.11653814],\n",
       "       [0.99970003, 0.        , 0.        , 0.        ],\n",
       "       [0.86228162, 0.        , 0.        , 0.1375187 ],\n",
       "       [0.79175214, 0.        , 0.20804842, 0.        ],\n",
       "       [0.79515412, 0.        , 0.17388319, 0.03086255],\n",
       "       [0.        , 0.        , 0.99730671, 0.00249289]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.pi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
